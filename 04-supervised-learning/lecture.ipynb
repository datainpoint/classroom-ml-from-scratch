{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python 機器學習從零至一\n",
    "\n",
    "> 監督式學習\n",
    "\n",
    "[數據交點](https://www.datainpoint.com/) | 郭耀仁 <yaojenkuo@datainpoint.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 這個章節會登場的模組\n",
    "\n",
    "`scikit-learn` 模組。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 現代資料科學：以程式設計做資料科學的應用\n",
    "\n",
    "![](r-for-data-science.png)\n",
    "\n",
    "來源：[R for Data Science](https://r4ds.had.co.nz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是資料科學的應用場景\n",
    "\n",
    "- Import 資料的載入。\n",
    "- Tidy 資料清理。\n",
    "- Transform 資料外型與類別的轉換。\n",
    "- Visualise 探索性分析。\n",
    "- **Model 分析與預測模型**。\n",
    "- Communicate 溝通分享。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## （複習）根據說明文件的範例載入\n",
    "\n",
    "多數時候我們使用 Scikit-Learn 中的特定類別或函數，因此以 `from sklearn import FUNCTION/CLASS` 載入特定類別或函數，而非 `import sklearn`\n",
    "\n",
    "來源：<https://scikit-learn.org/stable/getting_started.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 關於監督式學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是模型\n",
    "\n",
    "- 模型（Model）是一個類似於「函數」的概念，由參數與運算組成。\n",
    "- 模型的參數以及運算可以透過不同的方式生成，生成方式包含規則敘述與歷史資料訓練。\n",
    "    - 透過規則敘述生成參數以及運算，稱為基於規則的模型（Rule-based model）或稱專家模型。\n",
    "    - 透過歷史資料訓練生成參數以及運算，稱為基於演算法的模型（Algorithm-based model）或稱基於機器學習的模型。\n",
    "- 不同模型除了相互比較，也可以與基準（Baseline）模型比較，常用來作為基準模型的像是基於隨機的黑猩猩模型或稱虛假模型（Dummy model），像是以投擲硬幣、骰子或者射飛鏢來決定模型的輸出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 可以採用哪種模型解決問題\n",
    "\n",
    "- 採用基於規則的模型：\n",
    "    - 問題能用人類語言描述邏輯、撰寫規則。\n",
    "    - 答案不能容忍誤差。\n",
    "- 採用基於機器學習的模型：\n",
    "    - 問題非領域專家不容易描述邏輯、撰寫規則。\n",
    "    - 答案能夠容忍誤差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 可以採用哪種模型解決問題（續）\n",
    "\n",
    "- 採用基於規則的模型：給定整數判斷它是否為奇數、偶數或者質數。\n",
    "- 採用基於機器學習的模型：給定一位 NBA 球員的生涯場均助攻與場均籃板來猜他是中鋒、前鋒、後衛或者能夠打多個位置的搖擺人、中前鋒、雙能衛等鋒衛位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## （複習）機器學習的三個要素、一個但書\n",
    "\n",
    "> A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\n",
    "\n",
    "來源：[Machine Learning, Tom Mitchell, McGraw Hill, 1997](http://www.cs.cmu.edu/~tom/mlbook.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## （複習）以機器學習的電腦程式解決問題的方式示意圖\n",
    "\n",
    "![Imgur](https://i.imgur.com/YunyLd7.png)\n",
    "\n",
    "來源：<https://www.coursera.org/learn/introduction-tensorflow>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## （複習）給定答案 $y$ 以及資料 $X$，機器學習的電腦程式在最小化損失函數 $J$ 的前提下生成規則 $w$，進而獲得預測 $\\hat{y}$\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{choose} \\; w \\in \\{w^1, w^2, ..., w^n\\} \\\\\n",
    "\\text{where} \\; w \\; \\text{minimizes} \\; J(w) \\\\\n",
    "\\text{subject to} \\; \\hat{y} = h(X; w) = Xw \\\\\n",
    "\\text{where} \\; J(w) \\; \\text{measures the loss between} \\; y \\; \\text{and} \\; \\hat{y} \\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於機器學習的模型可再分為\n",
    "\n",
    "- 監督式學習：訓練資料中具備已實現的數值或標籤。\n",
    "    - 迴歸：數值預測的任務。\n",
    "    - 分類：類別預測的任務。\n",
    "- 非監督式學習：訓練資料中「不」具備已實現的數值或標籤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 數值預測的任務"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 數值預測的任務：迴歸模型\n",
    "\n",
    "- 「數值預測」是「監督式學習」的其中一種應用類型。\n",
    "- 預測的目標陣列 $y$ 屬於連續型數值變數。\n",
    "- 更常被稱為「迴歸模型」。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## （複習）預測數值時最常見的損失函數 $J$\n",
    "\n",
    "最小化訓練資料的均方誤差（Mean squared error）。\n",
    "\n",
    "\\begin{align}\n",
    "\\operatorname*{arg\\,min}_w \\;  J(w) =  \\frac{1}{m} \\sum_i^m (y_i^{(train)} - \\hat{y_i}^{(train)})^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 預測 NBA 球員的體重\n",
    "\n",
    "- 資料（Experience）：一定數量的球員資料。\n",
    "- 任務（Task）：利用模型預測球員的體重。\n",
    "- 評估（Performance）：模型預測的體重與球員實際體重的誤差大小。\n",
    "- 但書（Condition）：隨著資料觀測值筆數增加，預測誤差應該要減少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = \"https://raw.githubusercontent.com/datainpoint/classroom-ml-from-scratch/main/data/nba/player_stats.csv\"\n",
    "player_stats = pd.read_csv(csv_path)\n",
    "y = player_stats[\"weightKilograms\"].values\n",
    "y.dtype # y is a numeric variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何預測 NBA 球員的體重\n",
    "\n",
    "1. 虛假模型。\n",
    "2. 基於規則的專家模型。\n",
    "3. 基於機器學習的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 虛假模型\n",
    "\n",
    "在 NBA 球員體重全距之間取隨機整數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train, y_valid = train_test_split(y, test_size=0.33, random_state=42)\n",
    "y_max, y_min = y.max(), y.min()\n",
    "y_hat = np.random.randint(low=y_min, high=y_max, size=y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估虛假模型：驗證資料與預測資料的均方誤差\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MSE}_{valid} = \\frac{1}{m}\\sum_{i}^{m}{(y^{(valid)}_i - \\hat{y_i}^{(valid)})^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737.2324096385543"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_dummy = mean_squared_error(y_valid, y_hat)\n",
    "mse_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於規則的專家模型\n",
    "\n",
    "根據 NBA 球員的鋒衛位置取其平均體重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weight_by_pos = player_stats.groupby(\"pos\")[\"weightKilograms\"].mean()\n",
    "mean_weight = player_stats[\"pos\"].map(mean_weight_by_pos).values\n",
    "mean_weight_train, y_hat = train_test_split(mean_weight, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估基於規則的專家模型：驗證資料與預測資料的均方誤差\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MSE}_{valid} = \\frac{1}{m}\\sum_{i}^{m}{(y^{(valid)}_i - \\hat{y_i}^{(valid)})^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.668004006804765"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_expert = mean_squared_error(y_valid, y_hat)\n",
    "mse_expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於機器學習的模型\n",
    "\n",
    "將 `heightMeters` 當作特徵矩陣 $x_i$ 作為體重的預測依據。\n",
    "\n",
    "\\begin{equation}\n",
    "\\operatorname*{arg\\,min}_w \\; \\frac{1}{m}\\sum_{i}^{m}{(y^{(train)}_i - \\hat{y_i}^{(train)})^2} = \\frac{1}{m}\\sum_{i}^{m}{(y^{(train)}_i - x_i^{(train)} w)^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## （複習）使用 Scikit-Learn 預測器的標準步驟\n",
    "\n",
    "1. 準備欲訓練預測的特徵矩陣 $X$  與目標陣列 $y$\n",
    "2. 切割訓練與驗證資料。\n",
    "3. 建立預測器類別的物件。\n",
    "4. 將訓練特徵矩陣 $X^{train}$ 與目標陣列 $y^{train}$ 輸入 `predictor.fit()`\n",
    "5. 將驗證特徵矩陣 $X^{valid}$ 輸入 `predictor.predict()` 獲得 $\\hat{y}^{valid}$\n",
    "6. 比對 $\\hat{y}^{valid}$ 與 $y^{valid}$ 之間的差異。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = player_stats[\"heightMeters\"].values.reshape(-1, 1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n",
    "y_hat = linear_regression.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估基於機器學習的模型：驗證資料與預測資料的均方誤差\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MSE}_{valid} = \\frac{1}{m}\\sum_{i}^{m}{(y^{(valid)}_i - \\hat{y_i}^{(valid)})^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.807098266825335"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_ml = mean_squared_error(y_valid, y_hat)\n",
    "mse_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何預測 NBA 球員的體重：考量哪個模型驗證資料與預測資料的均方誤差最小\n",
    "\n",
    "1. 基於規則的專家模型。\n",
    "2. 基於機器學習的模型。\n",
    "3. 虛假模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.668004006804765\n",
      "62.807098266825335\n",
      "737.2324096385543\n"
     ]
    }
   ],
   "source": [
    "print(mse_expert)\n",
    "print(mse_ml)\n",
    "print(mse_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 類別預測的任務"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 類別預測的任務：分類器\n",
    "\n",
    "- 「類別預測」是「監督式學習」的其中一種應用類型。\n",
    "- 預測的目標陣列 $y$ 屬於離散型的類別變數。\n",
    "- 更常被稱為「分類器」。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## （複習）預測類別時最常見的損失函數 $J$\n",
    "\n",
    "最小化訓練資料的誤分類數。\n",
    "\n",
    "\\begin{align}\n",
    "\\operatorname*{arg\\,min}_w \\; J(w) = \\sum_j n(E^{(train)}_j) \\\\ \\text{ where } E^{(train)}_j \\; \\text{represents the occurrence of } y^{(train)}_j \\neq \\hat{y^{(train)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 預測 NBA 球員的鋒衛位置\n",
    "\n",
    "- 資料（Experience）：一定數量的球員資料。\n",
    "- 任務（Task）：利用模型預測球員的鋒衛位置。\n",
    "- 評估（Performance）：模型預測的鋒衛位置與球員實際鋒衛位置的誤分類數。\n",
    "- 但書（Condition）：隨著資料觀測值筆數增加，預測誤分類數應該要減少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# players_stats 資料中的 pos\n",
    "player_stats[\"pos\"].values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `player_stats` 資料中的 `pos` 有 7 個不同的類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'C' 'C-F' 'G' 'F-G' 'G-F' 'F-C']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(player_stats[\"pos\"].unique())\n",
    "print(player_stats[\"pos\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 先將多元分類問題簡化為二元分類問題\n",
    "\n",
    "- 鋒衛位置分作後衛（G）與前鋒（F）。\n",
    "- 分別對應整數 1 與整數 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_binary = player_stats[\"pos\"].map(lambda x: 0 if x[0] == \"G\" else 1)\n",
    "y = pos_binary.values\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何預測 NBA 球員的鋒衛位置\n",
    "\n",
    "1. 虛假模型。\n",
    "2. 基於規則的專家模型。\n",
    "3. 基於機器學習的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 虛假模型\n",
    "\n",
    "在 0 與 1 之間取隨機整數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid = train_test_split(y, test_size=0.33, random_state=42)\n",
    "y_hat = np.random.randint(0, 2, size=y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估虛假模型：驗證資料與預測資料的誤分類數\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Errors}^{(valid)} = \\sum_j n(E^{(valid)}_j) \\\\ \\text{ where } E^{(valid)}_j \\; \\text{represents the occurrence of } y^{(valid)}_j \\neq \\hat{y^{(valid)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "166\n",
      "0.5662650602409639\n"
     ]
    }
   ],
   "source": [
    "errors_dummy = np.sum(y_valid != y_hat)\n",
    "print(errors_dummy)\n",
    "print(y_valid.size)\n",
    "print(errors_dummy / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於規則的專家模型\n",
    "\n",
    "根據 NBA 球員的場均助攻數決定，場均助攻超過平均值則是 1，小於等於平均值則是 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_apg = player_stats[\"apg\"].mean()\n",
    "mean_apg_train_y_hat = player_stats[\"apg\"].map(lambda x: 0 if x > mean_apg else 1).values\n",
    "mean_apg_train, y_hat = train_test_split(mean_apg_train_y_hat, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估專家模型：驗證資料與預測資料的誤分類數\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Errors}^{(valid)} = \\sum_j n(E^{(valid)}_j) \\\\ \\text{ where } E^{(valid)}_j \\; \\text{represents the occurrence of } y^{(valid)}_j \\neq \\hat{y^{(valid)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "166\n",
      "0.3493975903614458\n"
     ]
    }
   ],
   "source": [
    "errors_expert = np.sum(y_valid != y_hat)\n",
    "print(errors_expert)\n",
    "print(y_valid.size)\n",
    "print(errors_expert / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於機器學習的模型\n",
    "\n",
    "將 `apg` 與 `rpg` 當作特徵矩陣 $X$ 作為鋒衛位置的預測依據。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## （複習）使用 Scikit-Learn 預測器的標準步驟\n",
    "\n",
    "1. 準備欲訓練預測的特徵矩陣 $X$  與目標陣列 $y$\n",
    "2. 切割訓練與驗證資料。\n",
    "3. 建立預測器類別的物件。\n",
    "4. 將訓練特徵矩陣 $X^{train}$ 與目標陣列 $y^{train}$ 輸入 `predictor.fit()`\n",
    "5. 將驗證特徵矩陣 $X^{valid}$ 輸入 `predictor.predict()` 獲得 $\\hat{y}^{valid}$\n",
    "6. 比對 $\\hat{y}^{valid}$ 與 $y^{valid}$ 之間的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = player_stats[[\"apg\", \"rpg\"]].values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_hat = logistic_regression.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估基於機器學習的模型：驗證資料與預測資料的誤分類數\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Errors}^{(valid)} = \\sum_j n(E^{(valid)}_j)\\\\ \\text{ where } E^{(valid)}_j \\; \\text{represents the occurrence of } y^{(valid)}_j \\neq \\hat{y^{(valid)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "166\n",
      "0.1686746987951807\n"
     ]
    }
   ],
   "source": [
    "errors_ml = np.sum(y_valid != y_hat)\n",
    "print(errors_ml)\n",
    "print(y_valid.size)\n",
    "print(errors_ml / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何預測 NBA 球員的鋒衛位置：考量哪個模型驗證資料與預測資料的誤分類數最少\n",
    "\n",
    "1. 機器學習模型。\n",
    "2. 專家模型。\n",
    "3. 虛假模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "28\n",
      "58\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "print(y_valid.size)\n",
    "print(errors_ml)\n",
    "print(errors_expert)\n",
    "print(errors_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 無法描述規則的任務"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 前面的數值、類別預測任務我們都有建立基於規則的專家模型\n",
    "\n",
    "- 有一些問題無法建立基於規則的專家模型，像是影像分類、語音識別或機器翻譯等，都屬於無法描述規則的任務。\n",
    "- 對人類來說影像分類、語音識別或語言翻譯是很輕易能辦到的，但要寫出其中的規則、邏輯是極其困難的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何處理無法描述規則的任務\n",
    "\n",
    "- 以機器學習領域的一個分支**深度學習**來處理。\n",
    "- 深度學習是一種不需要使用者**直接**決定特徵的最適化方法，而是由深度學習的結構**間接**決定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 辨識手寫數字圖片的數字\n",
    "\n",
    "- 資料（Experience）：一定數量的手寫數字圖片。\n",
    "- 任務（Task）：利用模型辨識手寫數字圖片的數字。\n",
    "- 評估（Performance）：模型辨識的數字與實際數字的誤分類數。\n",
    "- 但書（Condition）：隨著資料觀測值筆數增加，預測誤分類數應該要減少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 手寫數字圖片資料中的 `label` 有 10 個不同的類別（0-9）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_url = \"https://kaggle-getting-started.s3.ap-northeast-1.amazonaws.com/mnist/train.csv\"\n",
    "train = pd.read_csv(csv_url)\n",
    "train[\"label\"].values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 7 3 5 8 9 2 6]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(train[\"label\"].unique())\n",
    "print(train[\"label\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 看看前 10 列的手寫數字圖片\n",
    "\n",
    "使用 `AxesSubplot.imshow()` 顯示圖片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = 10\n",
    "fig, axes = plt.subplots(1, m)\n",
    "for index, series in train.head(m).iterrows():\n",
    "    Xi = (series[\"pixel0\":\"pixel783\"]).values.reshape(28, 28)\n",
    "    axes[index].imshow(Xi)\n",
    "    axes[index].set_xticks([]) # turn off xticks\n",
    "    axes[index].set_yticks([]) # turn off yticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 辨識手寫數字圖片的數字\n",
    "\n",
    "1. 虛假模型。\n",
    "2. ~~基於規則的專家模型。~~\n",
    "3. 基於深度學習的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 虛假模型\n",
    "\n",
    "在 0 與 9 之間取隨機整數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"label\"].values\n",
    "y_train, y_valid = train_test_split(y, test_size=0.33, random_state=42)\n",
    "y_hat = np.random.randint(0, 10, size=y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估虛假模型：驗證資料與預測資料的誤分類數\n",
    "\n",
    "\\begin{align}\n",
    "\\sum_j n(E^{(valid)}_j) \\text{ where } E^{(valid)}_j \\; \\text{represents the occurrence of } y^{(valid)}_j \\neq \\hat{y^{(valid)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12474\n",
      "13860\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "errors_dummy = np.sum(y_valid != y_hat)\n",
    "print(errors_dummy)\n",
    "print(y_valid.size)\n",
    "print(errors_dummy / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於深度學習的模型\n",
    "\n",
    "- 將 `pixel0` 到 `pixel783` 當作特徵矩陣 $X$ 作為手寫數字圖片的預測依據。\n",
    "- 我們對機器學習和深度學習都是點到為止，不暸解 `MLPClassifier` 參數是正常的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.43180376\n",
      "Iteration 2, loss = 0.20848267\n",
      "Iteration 3, loss = 0.15877069\n",
      "Iteration 4, loss = 0.12626574\n",
      "Iteration 5, loss = 0.10516230\n",
      "Iteration 6, loss = 0.08823135\n",
      "Iteration 7, loss = 0.07438078\n",
      "Iteration 8, loss = 0.06704161\n",
      "Iteration 9, loss = 0.05740887\n",
      "Iteration 10, loss = 0.04949325\n",
      "Iteration 11, loss = 0.04269057\n",
      "Iteration 12, loss = 0.03812857\n",
      "Iteration 13, loss = 0.03424393\n",
      "Iteration 14, loss = 0.02846397\n",
      "Iteration 15, loss = 0.02558921\n",
      "Iteration 16, loss = 0.02179269\n",
      "Iteration 17, loss = 0.01983708\n",
      "Iteration 18, loss = 0.01722650\n",
      "Iteration 19, loss = 0.01611390\n",
      "Iteration 20, loss = 0.01306801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuoyaojen/opt/miniconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = train.loc[:, \"pixel0\":\"pixel783\"].values.astype(float)\n",
    "X /= 255.0 # standardize X\n",
    "y = train[\"label\"].values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, alpha=1e-4, \n",
    "                               solver=\"sgd\", verbose=10, random_state=1,\n",
    "                               learning_rate_init=0.1)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "y_hat = mlp_classifier.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估深度學習的模型：驗證資料與預測資料的誤分類數\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Errors}^{(valid)} = \\sum_j n(E^{(valid)}_j) \\\\ \\text{ where } E^{(valid)}_j \\; \\text{represents the occurrence of } y^{(valid)}_j \\neq \\hat{y^{(valid)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n",
      "13860\n",
      "0.03383838383838384\n"
     ]
    }
   ],
   "source": [
    "errors_dl = np.sum(y_valid != y_hat)\n",
    "print(errors_dl)\n",
    "print(y_valid.size)\n",
    "print(errors_dl / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何辨識手寫數字圖片的數字：考量哪個模型驗證資料與預測資料的誤分類數最少\n",
    "\n",
    "1. 深度學習模型。\n",
    "2. 虛假模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13860\n",
      "469\n",
      "12474\n"
     ]
    }
   ],
   "source": [
    "print(y_valid.size)\n",
    "print(errors_dl)\n",
    "print(errors_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## k 最近鄰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是 k 最近鄰\n",
    "\n",
    "- k 最近鄰（k-Nearest Neighbors, KNN）是一種基於資料之間的相似度來決定是否為同一類別的演算方法。\n",
    "- 「歐幾里德距離 Euclidean distance」是最常用來量測資料相似度的指標，歐幾里德距離以白話文敘述其實就是直線距離。\n",
    "\n",
    "\\begin{align}\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是 k 最近鄰（續）\n",
    "\n",
    "- 更為泛用的距離量測是「明可夫斯基距離 Minkowski distance」。\n",
    "- 當式子中的 $p=1$ 時就是曼哈頓距離、$p=2$ 時就是歐幾里德距離。\n",
    "\n",
    "\\begin{align}\n",
    "d(x, y) = \\left( \\sum_{i=1}^{n} \\mid x_i - y_i \\mid ^p \\right)^{\\frac{1}{p}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是 k 最近鄰（續）\n",
    "\n",
    "- k 最近鄰會根據預測資料點周遭的 k 個最相似訓練資料點決定分類結果，k 可以由使用者自行決定。\n",
    "- 在二元分類的範疇下，k 會選擇一個奇數使得分類結果直接被決定。\n",
    "- k 最近鄰模型的訓練與預測在同時間發生，也就是訓練在輸入預測資料時才發生，因此屬於 Lazy learning 的機器學習方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 的 k 最近鄰預測器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = player_stats[[\"apg\", \"rpg\"]].values\n",
    "pos_binary = player_stats[\"pos\"].map(lambda x: 0 if x[0] == \"G\" else 1)\n",
    "y = pos_binary.values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "neigh = KNeighborsClassifier()\n",
    "neigh.fit(X_train, y_train)\n",
    "y_hat = neigh.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "166\n",
      "0.14457831325301204\n"
     ]
    }
   ],
   "source": [
    "errors_knn = np.sum(y_valid != y_hat)\n",
    "print(errors_knn)\n",
    "print(y_valid.size)\n",
    "print(errors_knn / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 自行定義 k 最近鄰預測器\n",
    "\n",
    "- 計算 `X_test_i` 與 `X_train` 的所有距離。\n",
    "- 將計算好的距離與 `y_train` 同時排序。\n",
    "- 依據 `k` 值選出前 `k` 小的標籤值。\n",
    "- 從前 `k` 小的標籤值中挑選最多的標籤作為 `y_test_i`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 計算 `X_test_i` 與 `X_train` 的所有距離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.30217289, 2.05912603, 1.74642492, 5.69385634, 2.54950976])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_i = np.array([[3.0, 5.0]]) # 場均 3.0 助攻、5.0 籃板\n",
    "p = 2\n",
    "distances = (np.sum((np.abs(X_test_i - X_train))**p, axis=1))**(1/p)\n",
    "distances[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 將計算好的距離與 `y_train` 同時排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42426407, 1.        ],\n",
       "       [0.4472136 , 1.        ],\n",
       "       [0.4472136 , 1.        ],\n",
       "       [0.53851648, 0.        ],\n",
       "       [0.58309519, 1.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_reshape = y_train.reshape(-1, 1)\n",
    "distances_reshape = distances.reshape(-1, 1)\n",
    "distances_y_train = np.concatenate((distances_reshape, y_train_reshape), axis=1)\n",
    "distances_y_train_argsort = distances_y_train[distances_y_train[:, 0].argsort()]\n",
    "distances_y_train_argsort[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 依據 `k` 值選出前 `k` 小的標籤值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "k_nearest_labels = distances_y_train_argsort[:k, 1].astype(int)\n",
    "k_nearest_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 從前 `k` 小的標籤值中挑選最多的標籤作為 `y_test_i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "argmax_counts = np.argmax(counts)\n",
    "y_test_i = labels[argmax_counts]\n",
    "print(y_test_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 自行定義 k 最近鄰預測器類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN:\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self._n_neighbors = n_neighbors\n",
    "    def minkowski_distances(self, X_train, X_test_i, p=2):\n",
    "        distances = (np.sum((np.abs(X_test_i - X_train))**p, axis=1))**(1/p)\n",
    "        return distances\n",
    "    def fit(self, X_train, y_train):\n",
    "        self._X_train = X_train\n",
    "        self._y_train = y_train\n",
    "    def predict(self, X_test, p=2):\n",
    "        nrows = X_test.shape[0]\n",
    "        y_test = []\n",
    "        for i in range(nrows):\n",
    "            X_test_i = X_test[i, :]\n",
    "            distances = self.minkowski_distances(self._X_train, X_test_i)\n",
    "            y_train_reshape = self._y_train.reshape(-1, 1)\n",
    "            distances_reshape = distances.reshape(-1, 1)\n",
    "            distances_y_train = np.concatenate((distances_reshape, y_train_reshape), axis=1)\n",
    "            distances_y_train_argsort = distances_y_train[distances_y_train[:, 0].argsort()]\n",
    "            k_nearest_labels = distances_y_train_argsort[:self._n_neighbors, 1].astype(int)\n",
    "            labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "            argmax_counts = np.argmax(counts)\n",
    "            y_test_i = labels[argmax_counts]\n",
    "            y_test.append(y_test_i)\n",
    "        return np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "knn = kNN()\n",
    "knn.fit(X_train, y_train)\n",
    "y_hat = knn.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "166\n",
      "0.14457831325301204\n"
     ]
    }
   ],
   "source": [
    "errors_knn = np.sum(y_valid != y_hat)\n",
    "print(errors_knn)\n",
    "print(y_valid.size)\n",
    "print(errors_knn / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 高斯單純貝氏分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是高斯單純貝氏分類器\n",
    "\n",
    "- 高斯單純貝氏分類器是基於貝氏定理的分類模型。\n",
    "- 貝氏定理是在先驗機率（Prior probability）的基礎上，納入新事件的資訊來更新先驗機率，得到後驗機率（Posterior probability）的統計分法。\n",
    "\n",
    "\\begin{align}\n",
    "P(y|x_i) = \\frac{P(x_i|y) \\times P(y)}{P(x_i)} \\\\\n",
    "\\text{posterior} = \\frac{\\text{likelihood} \\times \\text{prior}}{\\text{evidence}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是高斯單純貝氏分類器（續）\n",
    "\n",
    "- 高斯單純貝氏分類器中的「單純」指的是在計算分類機率時，會假設資料特徵不依賴類別，兩者彼此獨立。\n",
    "- 因此實際在計算後驗機率的時候，只需要關注分子的部分。\n",
    "\n",
    "\\begin{align}\n",
    "P(y|x_i) \\propto P(x_i|y) P(y) \\\\\n",
    "y^* = argmax_y \\, P(x_i|y) P(y) \\\\\n",
    "y^* = argmax_y \\, P(y) \\prod P(x_i|y)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是高斯單純貝氏分類器（續）\n",
    "\n",
    "當特徵為連續型變數時，可以藉由假設變數為常態分配的情況下，以樣本資料的平均數及標準差來計算機率（Likelihood），也就是 $P(x_i|y)$ 能以高斯機率密度函數計算。\n",
    "\n",
    "\\begin{align}\n",
    "P(x_i | y) = \\frac{1}{\\sqrt{2 \\pi \\sigma_y^2}} exp \\left( -\\frac{(x_i - \\mu_y)^2}{2 \\sigma_y^2} \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是高斯單純貝氏分類器（續）\n",
    "\n",
    "當特徵數量很多的時候，$\\prod P(x_i|y)$ 相乘所算出的機率值會非常小，造成後驗機率趨近於 0，這時可以透過取對數函數來避免。\n",
    "\n",
    "\\begin{align}\n",
    "y^* = argmax_y \\, log \\left(P(y) \\right) + \\sum log \\left( P(x_i|y) \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 的高斯單純貝氏分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = player_stats[[\"apg\", \"rpg\"]].values\n",
    "pos_binary = player_stats[\"pos\"].map(lambda x: 0 if x[0] == \"G\" else 1)\n",
    "y = pos_binary.values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_hat = nb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "166\n",
      "0.3072289156626506\n"
     ]
    }
   ],
   "source": [
    "errors_nb = np.sum(y_valid != y_hat)\n",
    "print(errors_nb)\n",
    "print(y_valid.size)\n",
    "print(errors_nb / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 自行定義高斯單純貝氏分類器\n",
    "\n",
    "- 依據 `y_train` 計算先驗機率 $P(y)$\n",
    "- 依據 `X_train` 與 `y_train`的分類計算個別的摘要，包含平均數與變異數。\n",
    "- 計算高斯機率密度 $P(x_i|y)$\n",
    "- 計算後驗機率 $P(y|x_i)$\n",
    "- 依據後驗機率預測 `y_test_i`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 依據 `y_train` 計算先驗機率 $P(y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4836795252225519\n",
      "0.516320474777448\n"
     ]
    }
   ],
   "source": [
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "n_y_zeros, n_y_ones = counts\n",
    "prior_proba_y_zero = n_y_zeros / y_train.size\n",
    "prior_proba_y_one = n_y_ones / y_train.size\n",
    "print(prior_proba_y_zero)\n",
    "print(prior_proba_y_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 依據 `X_train` 與 `y_train`的分類計算個別的摘要，包含平均數與變異數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.66319018 2.7       ]\n",
      "[1.34827586 4.70574713]\n",
      "[4.13876774 1.63668712]\n",
      "[0.91008323 5.57192099]\n"
     ]
    }
   ],
   "source": [
    "X_y_train = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "X_y_train_zero = X_y_train[X_y_train[:, -1] == 0]\n",
    "X_y_train_one = X_y_train[X_y_train[:, -1] == 1]\n",
    "X_train_zero_mean = np.mean(X_y_train_zero[:, 0:-1], axis=0)\n",
    "X_train_one_mean = np.mean(X_y_train_one[:, 0:-1], axis=0)\n",
    "X_train_zero_var = np.var(X_y_train_zero[:, 0:-1], axis=0)\n",
    "X_train_one_var = np.var(X_y_train_one[:, 0:-1], axis=0)\n",
    "print(X_train_zero_mean)\n",
    "print(X_train_one_mean)\n",
    "print(X_train_zero_var)\n",
    "print(X_train_one_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 計算高斯機率密度 $P(x_i|y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19342949 0.06195512]]\n",
      "[[0.09341543 0.16770007]]\n"
     ]
    }
   ],
   "source": [
    "X_test_i = np.array([[3.0, 5.0]]) # 場均 3.0 助攻、5.0 籃板\n",
    "multiplier_zero = 1 / np.sqrt(2 * np.pi * X_train_zero_var)\n",
    "proba_zero = np.exp(-((X_test_i - X_train_zero_mean)** 2 / (2 * X_train_zero_var)))\n",
    "X_test_i_gauss_zero = multiplier_zero * proba_zero\n",
    "multiplier_one = 1 / np.sqrt(2 * np.pi * X_train_one_var)\n",
    "proba_one = np.exp(-((X_test_i - X_train_one_mean)** 2 / (2 * X_train_one_var)))\n",
    "X_test_i_gauss_one = multiplier_one * proba_one\n",
    "print(X_test_i_gauss_zero)\n",
    "print(X_test_i_gauss_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 依據後驗機率預測 `y_test_i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_proba_y_zero = np.log(prior_proba_y_zero) + np.sum(np.log(X_test_i_gauss_zero))\n",
    "posterior_proba_y_one = np.log(prior_proba_y_one) + np.sum(np.log(X_test_i_gauss_one))\n",
    "posterior_proba = np.array([posterior_proba_y_zero, posterior_proba_y_one])\n",
    "y_test_i = np.argmax(posterior_proba)\n",
    "y_test_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 自行定義高斯單純貝氏分類器的類別\n",
    "\n",
    "```python\n",
    "class GaussianNaiveBayes:\n",
    "    def get_prior_proba(self, y_train):\n",
    "        values, counts = np.unique(y_train, return_counts=True)\n",
    "        prior_proba = dict()\n",
    "        for value, count in zip(values, counts):\n",
    "            prior_proba[value] = count / y_train.size\n",
    "        return prior_proba\n",
    "    def get_mean_var(self, X_train, y_train):\n",
    "        n_features = X_train.shape[1]\n",
    "        X_y_train = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        unique_labels = np.unique(y_train)\n",
    "        X_mean_var = dict()\n",
    "        for unique_label in unique_labels:\n",
    "            X_y_train_label = X_y_train[X_y_train[:, -1] == unique_label]\n",
    "            label_mean = np.mean(X_y_train_label[:, 0:-1], axis=0)\n",
    "            label_var = np.var(X_y_train_label[:, 0:-1], axis=0)\n",
    "            X_mean_var[unique_label] = {\n",
    "                \"mean\": label_mean,\n",
    "                \"var\": label_var\n",
    "            }\n",
    "        return X_mean_var\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "    def fit(self, X_train, y_train):\n",
    "        prior_proba = self.get_prior_proba(y_train)\n",
    "        mean_var = self.get_mean_var(X_train, y_train)\n",
    "        self._prior_proba = prior_proba\n",
    "        self._mean_var = mean_var\n",
    "    def get_likelihood(self, X_test_i, var, mean):\n",
    "        multiplier = 1 / np.sqrt(2 * np.pi * var)\n",
    "        numerator = (X_test_i - mean)**2\n",
    "        denominator = 2*var\n",
    "        exponenet = np.exp(- numerator / denominator)\n",
    "        likelihood = multiplier * exponenet\n",
    "        return likelihood\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "    def predict(self, X_test):\n",
    "        n_rows = X_test.shape[0]\n",
    "        labels = self._prior_proba.keys()\n",
    "        y_preds = []\n",
    "        for i in range(n_rows):\n",
    "            X_test_i = X_test[i, :]\n",
    "            log_posterior_probas = []\n",
    "            for label in labels:\n",
    "                label_var = self._mean_var[label][\"var\"]\n",
    "                label_mean = self._mean_var[label][\"mean\"]\n",
    "                likelihood = self.get_likelihood(X_test_i, label_var, label_mean)\n",
    "                log_likelihood = np.log(likelihood)\n",
    "                sum_log_likelihood = np.sum(log_likelihood)\n",
    "                log_prior_proba = np.log(self._prior_proba[label])\n",
    "                log_posterior_proba = log_prior_proba + sum_log_likelihood\n",
    "                log_posterior_probas.append(log_posterior_proba)\n",
    "            log_posterior_probas = np.array(log_posterior_probas)\n",
    "            y_pred = np.argmax(log_posterior_probas)\n",
    "            y_preds.append(y_pred)\n",
    "        return np.array(y_preds)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "    def get_prior_proba(self, y_train):\n",
    "        values, counts = np.unique(y_train, return_counts=True)\n",
    "        prior_proba = dict()\n",
    "        for value, count in zip(values, counts):\n",
    "            prior_proba[value] = count / y_train.size\n",
    "        return prior_proba\n",
    "    def get_mean_var(self, X_train, y_train):\n",
    "        n_features = X_train.shape[1]\n",
    "        X_y_train = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        unique_labels = np.unique(y_train)\n",
    "        X_mean_var = dict()\n",
    "        for unique_label in unique_labels:\n",
    "            X_y_train_label = X_y_train[X_y_train[:, -1] == unique_label]\n",
    "            label_mean = np.mean(X_y_train_label[:, 0:-1], axis=0)\n",
    "            label_var = np.var(X_y_train_label[:, 0:-1], axis=0)\n",
    "            X_mean_var[unique_label] = {\n",
    "                \"mean\": label_mean,\n",
    "                \"var\": label_var\n",
    "            }\n",
    "        return X_mean_var\n",
    "    def fit(self, X_train, y_train):\n",
    "        prior_proba = self.get_prior_proba(y_train)\n",
    "        mean_var = self.get_mean_var(X_train, y_train)\n",
    "        self._prior_proba = prior_proba\n",
    "        self._mean_var = mean_var\n",
    "    def get_likelihood(self, X_test_i, var, mean):\n",
    "        multiplier = 1 / np.sqrt(2 * np.pi * var)\n",
    "        numerator = (X_test_i - mean)**2\n",
    "        denominator = 2*var\n",
    "        exponenet = np.exp(- numerator / denominator)\n",
    "        likelihood = multiplier * exponenet\n",
    "        return likelihood\n",
    "    def predict(self, X_test):\n",
    "        n_rows = X_test.shape[0]\n",
    "        labels = self._prior_proba.keys()\n",
    "        y_preds = []\n",
    "        for i in range(n_rows):\n",
    "            X_test_i = X_test[i, :]\n",
    "            log_posterior_probas = []\n",
    "            for label in labels:\n",
    "                label_var = self._mean_var[label][\"var\"]\n",
    "                label_mean = self._mean_var[label][\"mean\"]\n",
    "                likelihood = self.get_likelihood(X_test_i, label_var, label_mean)\n",
    "                log_likelihood = np.log(likelihood)\n",
    "                sum_log_likelihood = np.sum(log_likelihood)\n",
    "                log_prior_proba = np.log(self._prior_proba[label])\n",
    "                log_posterior_proba = log_prior_proba + sum_log_likelihood\n",
    "                log_posterior_probas.append(log_posterior_proba)\n",
    "            log_posterior_probas = np.array(log_posterior_probas)\n",
    "            y_pred = np.argmax(log_posterior_probas)\n",
    "            y_preds.append(y_pred)\n",
    "        return np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = player_stats[[\"apg\", \"rpg\"]].values\n",
    "pos_binary = player_stats[\"pos\"].map(lambda x: 0 if x[0] == \"G\" else 1)\n",
    "y = pos_binary.values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "nb = GaussianNaiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "y_hat = nb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "166\n",
      "0.3072289156626506\n"
     ]
    }
   ],
   "source": [
    "errors_nb = np.sum(y_valid != y_hat)\n",
    "print(errors_nb)\n",
    "print(y_valid.size)\n",
    "print(errors_nb / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 重點統整\n",
    "\n",
    "- 模型（Model）是一個類似於「函數」的概念，由參數與運算組成。\n",
    "- 模型的參數以及運算可以透過不同的方式生成，生成方式包含規則敘述與歷史資料訓練。\n",
    "    - 透過規則敘述生成參數以及運算，稱為基於規則的模型（Rule-based model）或稱專家模型。\n",
    "    - 透過歷史資料訓練生成參數以及運算，稱為基於演算法的模型（Algorithm-based model）或稱基於機器學習的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 重點統整（續）\n",
    "\n",
    "- 採用基於規則的模型：\n",
    "    - 問題能用人類語言描述邏輯、撰寫規則。\n",
    "    - 答案不能容忍誤差。\n",
    "- 採用基於機器學習的模型：\n",
    "    - 問題非領域專家不容易描述邏輯、撰寫規則。\n",
    "    - 答案能夠容忍誤差。\n",
    "- 採用基於深度學習的模型：\n",
    "    - 問題完全不能用人類語言描述邏輯、撰寫規則。\n",
    "    - 答案能夠容忍誤差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 重點統整（續）\n",
    "\n",
    "- 監督式學習：訓練資料中具備已實現的數值或標籤。\n",
    "    - 迴歸：數值預測的任務。\n",
    "    - 分類：類別預測的任務。\n",
    "- 非監督式學習：訓練資料中「不」具備已實現的數值或標籤。\n",
    "- 如何選擇模型：考量哪個模型驗證資料與預測資料的誤差最少。\n",
    "    - 數值預測任務：均方誤差。\n",
    "    - 類別預測任務：誤分類數。"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
